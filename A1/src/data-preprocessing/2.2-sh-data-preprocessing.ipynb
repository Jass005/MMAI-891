{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import standard libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import random\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import needed libraries\n",
    "import nltk\n",
    "import gensim\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(os.path.join(os.getcwd(), \"..\", \"..\", \"data\", \"preprocessed\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the data\n",
    "df = pd.read_csv(\"2.1-sh-data-preprocessed.csv\", encoding = \"ISO-8859-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>cleaned_tweet</th>\n",
       "      <th>emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>.@wesley83 I have a 3G iPhone. After 3 hrs twe...</td>\n",
       "      <td>dead need upgrade station</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@jessedee Know about @fludapp ? Awesome iPad/i...</td>\n",
       "      <td>likely design also give free</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@swonderlin Can not wait for #iPad 2 also. The...</td>\n",
       "      <td>wait also sale</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@sxsw I hope this year's festival isn't as cra...</td>\n",
       "      <td>hope year festival year</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@sxtxstate great stuff on Fri #SXSW: Marissa M...</td>\n",
       "      <td>great stuff tech</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet  \\\n",
       "0  .@wesley83 I have a 3G iPhone. After 3 hrs twe...   \n",
       "1  @jessedee Know about @fludapp ? Awesome iPad/i...   \n",
       "2  @swonderlin Can not wait for #iPad 2 also. The...   \n",
       "3  @sxsw I hope this year's festival isn't as cra...   \n",
       "4  @sxtxstate great stuff on Fri #SXSW: Marissa M...   \n",
       "\n",
       "                  cleaned_tweet  emotion  \n",
       "0     dead need upgrade station        0  \n",
       "1  likely design also give free        2  \n",
       "2                wait also sale        2  \n",
       "3       hope year festival year        0  \n",
       "4              great stuff tech        2  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the data\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_tweet = df[\"cleaned_tweet\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = max(cleaned_tweet.apply(lambda text: len(nltk.word_tokenize(text))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of text features:  14\n"
     ]
    }
   ],
   "source": [
    "print(\"Total number of text features: \", num_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_vectorizer = sklearn.feature_extraction.text.CountVectorizer(min_df = 0.02,\n",
    "                                                                max_features = num_features,\n",
    "                                                                ngram_range = [1,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtm_tf = tf_vectorizer.fit_transform(cleaned_tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8976, 14)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtm_tf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_features = tf_vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_tweets = df[\"cleaned_tweet\"].apply(lambda x: [word for word in x.split() if word in tf_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                               []\n",
       "1                           [free]\n",
       "2                               []\n",
       "3                               []\n",
       "4                               []\n",
       "5                               []\n",
       "6                           [time]\n",
       "7                               []\n",
       "8                               []\n",
       "9                               []\n",
       "10                          [time]\n",
       "11                         [party]\n",
       "12                              []\n",
       "13                         [store]\n",
       "14                              []\n",
       "15                              []\n",
       "16                              []\n",
       "17                         [store]\n",
       "18                              []\n",
       "19                           [new]\n",
       "20                              []\n",
       "21                           [see]\n",
       "22                         [party]\n",
       "23                              []\n",
       "24                       [new, go]\n",
       "25                              []\n",
       "26                              []\n",
       "27                            [go]\n",
       "28                     [see, link]\n",
       "29                              []\n",
       "                   ...            \n",
       "8946                         [get]\n",
       "8947    [see, line, store, launch]\n",
       "8948                       [store]\n",
       "8949                       [store]\n",
       "8950                       [today]\n",
       "8951                       [party]\n",
       "8952                            []\n",
       "8953                    [see, get]\n",
       "8954                            []\n",
       "8955                   [get, link]\n",
       "8956                            []\n",
       "8957                        [link]\n",
       "8958                            []\n",
       "8959                        [link]\n",
       "8960                            []\n",
       "8961                        [link]\n",
       "8962                            []\n",
       "8963                       [today]\n",
       "8964       [launch, launch, today]\n",
       "8965            [line, open, link]\n",
       "8966                        [link]\n",
       "8967                        [link]\n",
       "8968                            []\n",
       "8969                            []\n",
       "8970                            []\n",
       "8971                        [link]\n",
       "8972                        [link]\n",
       "8973                            []\n",
       "8974                        [time]\n",
       "8975                        [link]\n",
       "Name: cleaned_tweet, Length: 8976, dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
